{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author - Ritvik Khanna \n",
    "# Date - 04/05/18 \n",
    "# Version - 2.3\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt #importing graph plotting functionality\n",
    "# import os\n",
    "# print(os.listdir(\"../input\"))\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"Datasets/car_evaluation.csv\", names = [\"buying\",\"maint\", \"doors\", \"persons\", \"lug_boot\",\"safety\",\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data\n",
    "\n",
    "Here, the dataset contains of 6 attributes and 1 class column having 4 class values{unacc, acc, good, vgood}. As we are building a neural network we need to provide the neural node values it can read and not bias over a specific value of an attribute. Therefore we convert all the nominal/categorical data into numeric by using **pandas.get_dummies** function. This function will create additional columns of each values corresponding to each attribute, therefore increasing the number of total columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1728, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying_high</th>\n",
       "      <th>buying_low</th>\n",
       "      <th>buying_med</th>\n",
       "      <th>buying_vhigh</th>\n",
       "      <th>maint_high</th>\n",
       "      <th>maint_low</th>\n",
       "      <th>maint_med</th>\n",
       "      <th>maint_vhigh</th>\n",
       "      <th>doors_2</th>\n",
       "      <th>doors_3</th>\n",
       "      <th>...</th>\n",
       "      <th>lug_boot_big</th>\n",
       "      <th>lug_boot_med</th>\n",
       "      <th>lug_boot_small</th>\n",
       "      <th>safety_high</th>\n",
       "      <th>safety_low</th>\n",
       "      <th>safety_med</th>\n",
       "      <th>class_acc</th>\n",
       "      <th>class_good</th>\n",
       "      <th>class_unacc</th>\n",
       "      <th>class_vgood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying_high  buying_low  buying_med  buying_vhigh  maint_high  maint_low  \\\n",
       "0            0           0           0             1           0          0   \n",
       "1            0           0           0             1           0          0   \n",
       "2            0           0           0             1           0          0   \n",
       "3            0           0           0             1           0          0   \n",
       "4            0           0           0             1           0          0   \n",
       "5            0           0           0             1           0          0   \n",
       "6            0           0           0             1           0          0   \n",
       "7            0           0           0             1           0          0   \n",
       "8            0           0           0             1           0          0   \n",
       "9            0           0           0             1           0          0   \n",
       "\n",
       "   maint_med  maint_vhigh  doors_2  doors_3     ...       lug_boot_big  \\\n",
       "0          0            1        1        0     ...                  0   \n",
       "1          0            1        1        0     ...                  0   \n",
       "2          0            1        1        0     ...                  0   \n",
       "3          0            1        1        0     ...                  0   \n",
       "4          0            1        1        0     ...                  0   \n",
       "5          0            1        1        0     ...                  0   \n",
       "6          0            1        1        0     ...                  1   \n",
       "7          0            1        1        0     ...                  1   \n",
       "8          0            1        1        0     ...                  1   \n",
       "9          0            1        1        0     ...                  0   \n",
       "\n",
       "   lug_boot_med  lug_boot_small  safety_high  safety_low  safety_med  \\\n",
       "0             0               1            0           1           0   \n",
       "1             0               1            0           0           1   \n",
       "2             0               1            1           0           0   \n",
       "3             1               0            0           1           0   \n",
       "4             1               0            0           0           1   \n",
       "5             1               0            1           0           0   \n",
       "6             0               0            0           1           0   \n",
       "7             0               0            0           0           1   \n",
       "8             0               0            1           0           0   \n",
       "9             0               1            0           1           0   \n",
       "\n",
       "   class_acc  class_good  class_unacc  class_vgood  \n",
       "0          0           0            1            0  \n",
       "1          0           0            1            0  \n",
       "2          0           0            1            0  \n",
       "3          0           0            1            0  \n",
       "4          0           0            1            0  \n",
       "5          0           0            1            0  \n",
       "6          0           0            1            0  \n",
       "7          0           0            1            0  \n",
       "8          0           0            1            0  \n",
       "9          0           0            1            0  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get_dummies() implementation\n",
    "category_col =[\"buying\",\"maint\", \"doors\", \"persons\", \"lug_boot\",\"safety\",\"class\"] \n",
    "df = pd.get_dummies(df, columns=category_col)\n",
    "df.to_csv('Datasets/car_evaluation_preprocessed.csv',index=False)\n",
    "## visualizing processed dataset\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dividing the dataset into Attribute and labels, then spliting into train and test using crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:1296 +  Test:432 = Total:1728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritvikkhanna/VirtualEnvironments/PyTorch/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype uint8 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, 0:21].values\n",
    "y = df.iloc[:, 21:].values\n",
    "## Normalizing data - Normalization refers to rescaling real valued numeric attributes into the range 0 and 1.\n",
    "X = preprocessing.scale(X)\n",
    "from sklearn.model_selection import train_test_split\n",
    "feature_train, feature_test, labels_train, labels_test = train_test_split(X, y, random_state = 42)\n",
    "print (\"Train:%d +  Test:%d = Total:%d\"  % (len(feature_train),len(feature_test),len(feature_train)+len(feature_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the NN classifier using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train_v = Variable(torch.FloatTensor(feature_train), requires_grad = False)\n",
    "labels_train_v = Variable(torch.FloatTensor(labels_train), requires_grad = False)\n",
    "feature_test_v = Variable(torch.FloatTensor(feature_test), requires_grad = False)\n",
    "labels_test_v = Variable(torch.FloatTensor(labels_test), requires_grad = False)\n",
    "\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.h_layer = nn.Linear(21, 4) #21 input layers and 4 output layers\n",
    "        self.s_layer = nn.Softmax()\n",
    "    def forward(self,x):\n",
    "        y = self.h_layer(x)\n",
    "        p = self.s_layer(y)\n",
    "        return p\n",
    "#declaring the classifier to an object\n",
    "model = LinearClassifier()   \n",
    "#calculates the loss\n",
    "loss_fn = nn.BCELoss()       \n",
    "optim = torch.optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we fit the raining data into the model, here we do 5000 iterations and collect the loss of each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritvikkhanna/VirtualEnvironments/PyTorch/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "all_losses = []\n",
    "for num in range(5000): \n",
    "    pred = model(feature_train_v) #predict\n",
    "    loss = loss_fn(pred, labels_train_v) #calculate loss\n",
    "    all_losses.append(loss.data)\n",
    "    optim.zero_grad() #zero gradients to not accumulate\n",
    "    loss.backward() #update weights based on loss\n",
    "    optim.step() #update optimiser for next iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the loss per each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.4646,  0.0828,  0.4012,  0.0514])\n",
      "tensor([ 1.,  0.,  0.,  0.])\n",
      "0.16767245531082153\n"
     ]
    }
   ],
   "source": [
    "all_losses = np.array(all_losses, dtype = np.float)\n",
    "all_losses\n",
    "plt.plot(all_losses)\n",
    "plt.show()\n",
    "print(pred[3])\n",
    "print(labels_train_v[3])\n",
    "print(all_losses[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy result from testing data on the model\n",
    "\n",
    "Now we fit the test dataset on our model and find the score of each correctly labeled data by the Neural Network model and find the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy Score is 86.3425925925926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritvikkhanna/VirtualEnvironments/PyTorch/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predicted_values = []\n",
    "for num in range(len(feature_test_v)):\n",
    "    predicted_values.append(model(feature_test_v[num]))\n",
    "\n",
    "    \n",
    "    score = 0\n",
    "for num in range(len(predicted_values)):\n",
    "    if np.argmax(labels_test[num]) == np.argmax(predicted_values[num].data.numpy()):\n",
    "        score = score + 1\n",
    "accuracy = float(score / len(predicted_values)) * 100\n",
    "print ('Testing Accuracy Score is ' + str(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
