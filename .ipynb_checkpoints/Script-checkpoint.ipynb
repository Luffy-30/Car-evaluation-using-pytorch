{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author - Ritvik Khanna \n",
    "# Date - 04/05/18 \n",
    "# Version - 2.3\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt #importing graph plotting functionality\n",
    "# import os\n",
    "# print(os.listdir(\"../input\"))\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"Datasets/car_evaluation.csv\", names = [\"buying\",\"maint\", \"doors\", \"persons\", \"lug_boot\",\"safety\",\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data\n",
    "\n",
    "Here, the dataset contains of 6 attributes and 1 class column having 4 class values{unacc, acc, good, vgood}. As we are building a neural network we need to provide the neural node values it can read and not bias over a specific value of an attribute. Therefore we convert all the nominal/categorical data into numeric by using **pandas.get_dummies** function. This function will create additional columns of each values corresponding to each attribute, therefore increasing the number of total columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1728, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying_high</th>\n",
       "      <th>buying_low</th>\n",
       "      <th>buying_med</th>\n",
       "      <th>buying_vhigh</th>\n",
       "      <th>maint_high</th>\n",
       "      <th>maint_low</th>\n",
       "      <th>maint_med</th>\n",
       "      <th>maint_vhigh</th>\n",
       "      <th>doors_2</th>\n",
       "      <th>doors_3</th>\n",
       "      <th>...</th>\n",
       "      <th>lug_boot_big</th>\n",
       "      <th>lug_boot_med</th>\n",
       "      <th>lug_boot_small</th>\n",
       "      <th>safety_high</th>\n",
       "      <th>safety_low</th>\n",
       "      <th>safety_med</th>\n",
       "      <th>class_acc</th>\n",
       "      <th>class_good</th>\n",
       "      <th>class_unacc</th>\n",
       "      <th>class_vgood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying_high  buying_low  buying_med  buying_vhigh  maint_high  maint_low  \\\n",
       "0            0           0           0             1           0          0   \n",
       "1            0           0           0             1           0          0   \n",
       "2            0           0           0             1           0          0   \n",
       "3            0           0           0             1           0          0   \n",
       "4            0           0           0             1           0          0   \n",
       "5            0           0           0             1           0          0   \n",
       "6            0           0           0             1           0          0   \n",
       "7            0           0           0             1           0          0   \n",
       "8            0           0           0             1           0          0   \n",
       "9            0           0           0             1           0          0   \n",
       "\n",
       "   maint_med  maint_vhigh  doors_2  doors_3     ...       lug_boot_big  \\\n",
       "0          0            1        1        0     ...                  0   \n",
       "1          0            1        1        0     ...                  0   \n",
       "2          0            1        1        0     ...                  0   \n",
       "3          0            1        1        0     ...                  0   \n",
       "4          0            1        1        0     ...                  0   \n",
       "5          0            1        1        0     ...                  0   \n",
       "6          0            1        1        0     ...                  1   \n",
       "7          0            1        1        0     ...                  1   \n",
       "8          0            1        1        0     ...                  1   \n",
       "9          0            1        1        0     ...                  0   \n",
       "\n",
       "   lug_boot_med  lug_boot_small  safety_high  safety_low  safety_med  \\\n",
       "0             0               1            0           1           0   \n",
       "1             0               1            0           0           1   \n",
       "2             0               1            1           0           0   \n",
       "3             1               0            0           1           0   \n",
       "4             1               0            0           0           1   \n",
       "5             1               0            1           0           0   \n",
       "6             0               0            0           1           0   \n",
       "7             0               0            0           0           1   \n",
       "8             0               0            1           0           0   \n",
       "9             0               1            0           1           0   \n",
       "\n",
       "   class_acc  class_good  class_unacc  class_vgood  \n",
       "0          0           0            1            0  \n",
       "1          0           0            1            0  \n",
       "2          0           0            1            0  \n",
       "3          0           0            1            0  \n",
       "4          0           0            1            0  \n",
       "5          0           0            1            0  \n",
       "6          0           0            1            0  \n",
       "7          0           0            1            0  \n",
       "8          0           0            1            0  \n",
       "9          0           0            1            0  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get_dummies() implementation\n",
    "category_col =[\"buying\",\"maint\", \"doors\", \"persons\", \"lug_boot\",\"safety\",\"class\"] \n",
    "df = pd.get_dummies(df, columns=category_col)\n",
    "df.to_csv('Datasets/car_evaluation_preprocessed.csv',index=False)\n",
    "## visualizing processed dataset\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dividing the dataset into Attribute and labels, then spliting into train and test using crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:1296 +  Test:432 = Total:1728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritvikkhanna/VirtualEnvironments/PyTorch/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype uint8 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, 0:21].values\n",
    "y = df.iloc[:, 21:].values\n",
    "## Normalizing data - Normalization refers to rescaling real valued numeric attributes into the range 0 and 1.\n",
    "X = preprocessing.scale(X)\n",
    "from sklearn.model_selection import train_test_split\n",
    "feature_train, feature_test, labels_train, labels_test = train_test_split(X, y, random_state = 42)\n",
    "print (\"Train:%d +  Test:%d = Total:%d\"  % (len(feature_train),len(feature_test),len(feature_train)+len(feature_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the NN classifier using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train_v = Variable(torch.FloatTensor(feature_train), requires_grad = False)\n",
    "labels_train_v = Variable(torch.FloatTensor(labels_train), requires_grad = False)\n",
    "feature_test_v = Variable(torch.FloatTensor(feature_test), requires_grad = False)\n",
    "labels_test_v = Variable(torch.FloatTensor(labels_test), requires_grad = False)\n",
    "\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.h_layer = nn.Linear(21, 4) #21 input layers and 4 output layers\n",
    "        self.s_layer = nn.Softmax()\n",
    "    def forward(self,x):\n",
    "        y = self.h_layer(x)\n",
    "        p = self.s_layer(y)\n",
    "        return p\n",
    "#declaring the classifier to an object\n",
    "model = LinearClassifier()   \n",
    "#calculates the loss\n",
    "loss_fn = nn.BCELoss()       \n",
    "optim = torch.optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we fit the raining data into the model, here we do 5000 iterations and collect the loss of each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritvikkhanna/VirtualEnvironments/PyTorch/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "all_losses = []\n",
    "for num in range(5000): \n",
    "    pred = model(feature_train_v) #predict\n",
    "    loss = loss_fn(pred, labels_train_v) #calculate loss\n",
    "    all_losses.append(loss.data)\n",
    "    optim.zero_grad() #zero gradients to not accumulate\n",
    "    loss.backward() #update weights based on loss\n",
    "    optim.step() #update optimiser for next iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the loss per each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAH2ZJREFUeJzt3Xl0nXd95/H3927a98WWLdmSYzuxkzhOkE1WskBoAozTNixOyyFszYGSoYV2hqRMM5SZOQPplOmWAVKgMB1o2Ap1IMQNJECSJo7lON7tWN4lL5JlbZZ0tf7mj/tIuRaydW0tj+5zP69z7rnP87s/635/Otef++j3bOacQ0REgiXkdwEiIjL9FO4iIgGkcBcRCSCFu4hIACncRUQCSOEuIhJACncRkQBSuIuIBJDCXUQkgCJ+vXF5ebmrra316+1FRNLSli1bTjvnKibr51u419bW0tDQ4Nfbi4ikJTM7kko/TcuIiASQwl1EJIAU7iIiAaRwFxEJIIW7iEgAKdxFRAJI4S4iEkBpF+4Nh8/wxaf3otsDioicX9qF+87mTr78ywOc7Ir7XYqIyJyVduG+qqYYgG3HOn2uRERk7kq7cF9ZVUgkZGxv6vC7FBGROSvtwj07Guby+QVsb9KWu4jI+aRduAOsqi5me1OHdqqKiJxHWob7NdVFdMWHONLW63cpIiJzUlqG+9XVRQBs07y7iMiE0jLcl88rICsS0ry7iMh5pGW4R8MhrlxQqCNmRETOIy3DHRI7VXc2dzE0POJ3KSIic07ahvs1NUX0DQ5zoLXH71JEROactA33VdXemaqamhER+Q0phbuZ3WVm+8ys0cweOk+f95rZbjPbZWbfmd4yf1NdWR4FWRHNu4uITCAyWQczCwOPAXcCTcBmM9vgnNud1GcZ8DBwk3Ou3cwqZ6rgUaGQcdXCIh0xIyIygVS23NcCjc65g865AeAJ4J5xff4AeMw51w7gnGuZ3jIntqqmiD0nuugfGp6NtxMRSRuphPtC4FjSepPXlmw5sNzMXjSzl83srol+kJk9YGYNZtbQ2tp6aRUnuaa6mMFhx76T3VP+WSIiQTJdO1QjwDLgNuA+4B/MrHh8J+fc4865eudcfUVFxZTfdNXYmaqamhERSZZKuDcDNUnr1V5bsiZgg3Nu0Dl3CHidRNjPqIXFOZTlxdh+TDtVRUSSpRLum4FlZlZnZjFgPbBhXJ8fk9hqx8zKSUzTHJzGOidkZqyqLtLhkCIi40wa7s65IeBBYCOwB/iec26XmX3ezNZ53TYCbWa2G3gO+E/OubaZKjrZ6poS9recpTs+OBtvJyKSFiY9FBLAOfcU8NS4tkeSlh3wae8xq65bXIxzsL2pk5uWls/224uIzElpe4bqqGtqijGDV4+0+12KiMickfbhXpgdZWlFPlu1U1VEZEzahzvAtYuK2Xq0XbfdExHxBCTcS2jvHdRt90REPIEI9+sWlQCw9Zjm3UVEICDhvrQyn/ysCK8e0by7iAgEJNzDIeOamiJtuYuIeAIR7gDX1pSw50Q3fQO6QqSISHDCfVExwyOOHc26iJiISIDCPbFT9dWjmpoREQlMuJfmxagty2Wrwl1EJDjhDomt91ePduhkJhHJeAEL92Jau/s53hn3uxQREV8FK9xrvHl3XURMRDJcoML9iqoCcqJhtijcRSTDBSrco+EQ1y4qZvPhM36XIiLiq0CFO0B9bSl7TnTpzkwiktECF+5ra0sZcbD1qK4zIyKZK3DhvnpRMeGQ0aCpGRHJYIEL9/ysCCurCtl8WDtVRSRzBS7cAeprS9h6rJ3B4RG/SxER8UUgw31NbSnxwRF2He/yuxQREV8EMtzrFydOZtp8SPPuIpKZAhnulYXZLC7L1fHuIpKxAhnuAPWLS2k40q6LiIlIRgpsuK+pLeFMzwAHT/f4XYqIyKwLbrjXlQLoeHcRyUiBDfcl5XmU5sV45ZCOdxeRzBPYcDcz1taWsulQm9+liIjMusCGO8D1S0ppau/j2Jlev0sREZlVgQ73Gy4rB+Clg9p6F5HMEuhwXz4vn9K8GC8r3EUkwwQ63M2M65eU8vKBNh3vLiIZJaVwN7O7zGyfmTWa2UMTvP5BM2s1s9e8x0env9RLc8OSMo53xjmqeXcRySCRyTqYWRh4DLgTaAI2m9kG59zucV2/65x7cAZqnJIbLisD4KUDbSwuy/O5GhGR2ZHKlvtaoNE5d9A5NwA8Adwzs2VNn8sq8qkoyNK8u4hklFTCfSFwLGm9yWsb714z225mPzCzmmmpbhok5t3LeOmg5t1FJHNM1w7VJ4Fa59wq4BngWxN1MrMHzKzBzBpaW1un6a0nd/2SUk519XNI15kRkQyRSrg3A8lb4tVe2xjnXJtzrt9b/Rrwpol+kHPucedcvXOuvqKi4lLqvSQ3LPHm3TU1IyIZIpVw3wwsM7M6M4sB64ENyR3MrCppdR2wZ/pKnLq68jzmFWbx8kFdRExEMsOkR8s454bM7EFgIxAGvuGc22VmnwcanHMbgE+a2TpgCDgDfHAGa75oZsYNS8p4oTEx725mfpckIjKjJg13AOfcU8BT49oeSVp+GHh4ekubXjctLefHrx1n78luVlQV+l2OiMiMCvQZqsluWZaY439+/+ztyBUR8UvGhPv8omyWz8vn+f2n/S5FRGTGZUy4A7xlWQWbDp0hPjjsdykiIjMqo8L9luUVDAyNsOmQjpoRkWDLqHBfW1tKLBLi+dc17y4iwZZR4Z4TC7O2tlTz7iISeBkV7gC3LCtn36luTnXF/S5FRGTGZGC4jx4Sqa13EQmujAv3K+YXUJ6fxa817y4iAZZx4R4KGW9ZVs6v97cyPKJLAItIMGVcuAPcsaKSjt5Bth5t97sUEZEZkZHhfsuyCiIh4xd7W/wuRURkRmRkuBflRFlTW8qzexTuIhJMGRnuAG9dUcm+U90cO9PrdykiItMuY8P9jisqAXhun7beRSR4Mjbcl1TkU1eexy80NSMiAZSx4Q6JrfeXDrTR0z/kdykiItMqo8P9rVdUMjA8wouNOltVRIIlo8O9vraUgqwIz+w+5XcpIiLTKqPDPRYJcceKSn6+5xRDwyN+lyMiMm0yOtwB7r5qPu29g7qBh4gESsaH+63LK8mJhvnZzhN+lyIiMm0yPtxzYmFuu7yCjbtOMaILiYlIQGR8uAPcddV8Wrv72aILiYlIQCjcSRzvHguHeHrnSb9LERGZFgp3oCA7yi3Lynl650mc09SMiKQ/hbvnrqvm09zRx47mTr9LERGZMoW7586V84iGjSe3Hfe7FBGRKVO4e4pzY9y6vIIN247r9nsikvYU7knuWb2QU139bDrU5ncpIiJTonBP8rYV88iLhfnXrZqaEZH0pnBPkhML81tXzeepnSeIDw77XY6IyCVTuI/z26sX0h0f4pe6Q5OIpLGUwt3M7jKzfWbWaGYPXaDfvWbmzKx++kqcXTdeVkZ5fowfa2pGRNLYpOFuZmHgMeBuYCVwn5mtnKBfAfBHwKbpLnI2RcIh3rVqAc/ubaGjd8DvckRELkkqW+5rgUbn3EHn3ADwBHDPBP3+G/BFID6N9fniPfXVDAyP8OOtzX6XIiJySVIJ94XAsaT1Jq9tjJldB9Q45346jbX55soFRVy1sJDvNjTpcgQikpamvEPVzELAl4A/SaHvA2bWYGYNra2tU33rGfW+NYvYc6KLnc1dfpciInLRUgn3ZqAmab3aaxtVAFwF/NLMDgPXAxsm2qnqnHvcOVfvnKuvqKi49KpnwbprFpAVCfHE5qN+lyIictFSCffNwDIzqzOzGLAe2DD6onOu0zlX7pyrdc7VAi8D65xzDTNS8Swpyonyjqur2PDacfoGdMy7iKSXScPdOTcEPAhsBPYA33PO7TKzz5vZupku0E/vW1NDd/8QT+3QLfhEJL1EUunknHsKeGpc2yPn6Xvb1MuaG95cV0pdeR7f3nSEe99U7Xc5IiIp0xmqF2BmvP/6xbx6tIMdTbrOu4ikD4X7JN5TX01uLMw3//2w36WIiKRM4T6Jwuwo915XzZPbj9N2tt/vckREUqJwT8H9Ny5mYGiEJzYfm7yziMgcoHBPwdLKAm5eWs7/e/kIQ8MjfpcjIjIphXuKPnhjLSc64/xUh0WKSBpQuKfojisquawij6/86qCuNyMic57CPUWhkPGxWy9jz4kufvX63L4ujoiIwv0i3LN6IVVF2Xz5lwf8LkVE5IIU7hchFgnxB7csYdOhM2w50u53OSIi56Vwv0jr19ZQnBvV1ruIzGkK94uUG4vwoRvr+PmeU+xs1iUJRGRuUrhfgg/fXEtxbpS/+rd9fpciIjIhhfslKMiO8rFbL+O5fa1sOXLG73JERH6Dwv0SfeCGxZTnZ/G/Nr7udykiIr9B4X6JcmMRPnH7Zbx0sI0XG0/7XY6IyDkU7lNw39pFLCjK5gs/28vIiM5aFZG5Q+E+BdnRMJ+5+wp2NHfyw1eb/C5HRGSMwn2K1l2zgNU1xTy6cR89/UN+lyMiAijcp8zMeOQ/rKS1u18nNonInKFwnwbXLSrhntULePz5gxw70+t3OSIiCvfp8pm7riBsxn/dsEuXBBYR3yncp8mC4hw+fedynt3bwlM7TvpdjohkOIX7NPrQTbVcuaCQzz25i86+Qb/LEZEMpnCfRpFwiC/87irazvbz6NN7/S5HRDKYwn2aXV1dxAdvrOPbm47y0oE2v8sRkQylcJ8Bf/pby6krz+NPv7+NrrimZ0Rk9incZ0BuLMKX3nsNJ7vifG7DLr/LEZEMpHCfIdcuKuETty/lX15t5qkdJ/wuR0QyjMJ9Bv3HO5ayqrqIP/vRDpo7+vwuR0QyiMJ9BkXDIf5m/bUMDTs+8e1XGRga8bskEckQCvcZVleex6PvXsVrxzr4Hz/d7Xc5IpIhFO6z4B1XV/GRm+v41ktH2LDtuN/liEgGSCnczewuM9tnZo1m9tAEr3/MzHaY2Wtm9oKZrZz+UtPbQ3dfwZsWl/CZH2xnZ3On3+WISMBNGu5mFgYeA+4GVgL3TRDe33HOXe2cWw08Cnxp2itNc9FwiC///nUU50b56LcaONUV97skEQmwVLbc1wKNzrmDzrkB4AngnuQOzrmupNU8QJdFnEBlYTZfv38N3fFBPvqtBnoHdHMPEZkZqYT7QuBY0nqT13YOM/uEmR0gseX+yekpL3hWLijkb++7ll3HO/nUd19jWPdeFZEZMG07VJ1zjznnLgM+A/yXifqY2QNm1mBmDa2trdP11mnnrSvm8efvWsnGXaf47I926PrvIjLtIin0aQZqktarvbbzeQL48kQvOOceBx4HqK+vz+hE+9BNdbT3DPC3zzaSnxXhs+9cgZn5XZaIBEQq4b4ZWGZmdSRCfT3we8kdzGyZc26/t/pOYD8yqU/duZyu+BBfe+EQhTlRPvnWZX6XJCIBMWm4O+eGzOxBYCMQBr7hnNtlZp8HGpxzG4AHzextwCDQDtw/k0UHhZnxyLtW0h0f4kvPvE44ZHzi9qV+lyUiAZDKljvOuaeAp8a1PZK0/EfTXFfGCIWML957NcMjI/zlxn3EB4f59J3LNUUjIlOSUrjLzIqEQ/zVe1eTFQnzd882Eh8c5s/eoTl4Ebl0Cvc5Ihwy/ufvXk12NMQ/PH+Irr4h/vvvXEU0rCtEiMjFU7jPIaGQ8bl1V1KYE+Xvnm3kRFecx37vWgqyo36XJiJpRpuFc4yZ8Sdvv5wv3ns1Lzae5r1ffZmTnbpUgYhcHIX7HPW+NYv4xgfXcLSth3see4EtR9r9LklE0ojCfQ67dXkFP/j4jWRFwqx//CW+vemIzmYVkZQo3Oe4FVWFPPngzdy0tJzP/mgnn/nhduKDw36XJSJznMI9DRTlRvn6/Wv45B1L+V5DE/f8/YvsPdk1+T8UkYylcE8T4ZDx6bdfzrc+vJa2ngHW/f2LfPPFQ5qmEZEJKdzTzK3LK3j6j2/h5qXlfO7J3Xzom5s53tHnd1kiMsco3NNQeX4WX7+/ns/fcyWbDp7h7f/71/zTy0cY0bXhRcSjcE9TZsYHbqjl3z71FlbXFPPnP97J+sdf5mDrWb9LE5E5QOGe5mpKc/mnj6zl0XevYu/JLu766+d59Om99PTrFn4imUzhHgBmxnvra/j5n9zKu1ZV8X9+eYA7/uqX/Ghrk3a4imQohXuAVBZk86X3reaHH7+ReYXZfOq727j3y//O5sNn/C5NRGaZwj2A3rS4hB//4U08+u5VHGvv4z1feYkP/uMr7Gzu9Ls0EZkl5tef7fX19a6hocGX984kfQPDfOulw3zlVwfo6B3knVdX8ak7l7O0Mt/v0kTkEpjZFudc/aT9FO6ZoSs+yNeeP8TXnz9I7+Awd181n4/dehmrqov9Lk1ELoLCXSbUdrafb7x4iP/70hG640PcvLScj916GTctLdOdn0TSgMJdLqg7Psh3Nh3lay8corW7nysXFHL/DbWsW72A7GjY7/JE5DwU7pKS+OAwP9razD++eIjXT52lODfKe+treP+bF7OoLNfv8kRkHIW7XBTnHJsOneGfXjrC07tOMuIcty2vYP3aRdx+eSWxiA6sEpkLFO5yyU51xfnOpqP88ytHaenupzQvxj2rF/DuN1Vz5YIiv8sTyWgKd5myoeERnt9/mh9saeKZ3acYGB5hRVUhv3PtAt65agELi3P8LlEk4yjcZVp19A6wYdtxfrClie1NiZOhrltUzLtWLeCdq6qYV5jtc4UimUHhLjPm8OkefrrjBE9uO87ek92YwZrFpdy5ch5vXVHJkgqdICUyUxTuMisaW87y0+0n+NnOE+w92Q3Akoo87lwxj7eumMd1i4qJhLUzVmS6KNxl1jW19/KLPS38fM8pXj7YxuCwoyQ3yu2XV3LL8nJuuqycSk3fiEyJwl181R0f5Nevn+YXe07x3L4W2nsHAVg+L5+bl1Zw87Iy1taVkZ8V8blSkfSicJc5Y2TEsftEFy80nubFxtO8cugM/UMjRELGtYuKuWlpOW+uK2N1TTE5MZ0dK3IhCneZs+KDw2w50j4W9juaO3EOomHjqoVFrKktZU1tKfWLSyjJi/ldrsiconCXtNHZO8iWo2d45VA7DYfPsL2pk4HhEQCWVuazpraE1TXFXFNTzLLKAsIhXeBMMpfCXdJWfHCY7U2dbD58hobDZ9hypJ2ueOKesLmxMFctLEqEfXUxq6qLqC7J0RUtJWOkGu7amyVzTnY0zNq6UtbWlQKJOfsjZ3rZdqyD1451sK2pg2/++2EGhhJb92V5MVYuKEw8qgq5ckEhdeX52sKXjJZSuJvZXcDfAGHga865L4x7/dPAR4EhoBX4sHPuyDTXKhkqFDLqyvOoK8/jt69dCMDA0Aj7TnbzWlMH2491sPtEF//4wuGx6ZzsaIjL5xWMBf7KBYVcMb+QPB2dIxli0mkZMwsDrwN3Ak3AZuA+59zupD63A5ucc71m9nHgNufc+y70czUtI9NtYGiEA61n2XOii93Hu9h9ootdx7vo7Bsc61NdksOyynyWzStgaWU+yyrzWVqZT0F21MfKRVI3ndMya4FG59xB7wc/AdwDjIW7c+65pP4vA++/uHJFpi4WCbGiqpAVVYX87nWJNuccJzrj7D7exZ4TXexvOcv+lrO8eKBtbFoHoKoo2wt7L/Tn5bO0Il9H60jaSiXcFwLHktabgDdfoP9HgJ9N9IKZPQA8ALBo0aIUSxS5dGbGguIcFhTn8LaV88bah0ccx8700uiF/f6WbhpbzvLPrxylb3B4rF9RTpTa8jxqy3JZXJZHXbn3XJZHcW5UO3JlzprWCUgzez9QD9w60evOuceBxyExLTOd7y1yMcIhS4R2ed45oT8y4jje2cf+lrMcaDnL4bYeDp/uZcuRdjZsO07yLGZhdoS68jwWl+WNfQHUluexuDSX0ryYgl98lUq4NwM1SevVXts5zOxtwGeBW51z/dNTnsjsCoWM6pJcqktyuf3yynNe6x8a5tiZPg6f7kmEflsPR9p6efVoOz/ZfpyRpODPiYapLsnxHrnjnnMU/jLjUgn3zcAyM6sjEerrgd9L7mBm1wJfBe5yzrVMe5Uic0BWJMxSbwfseKPBf6Sth8NtvTS399HU3ktTe985x+mPyomGWTgW/ongryrKpqooh6qibCoLs8iK6FIMcukmDXfn3JCZPQhsJHEo5Decc7vM7PNAg3NuA/CXQD7wfW9r5Khzbt0M1i0yp1wo+AG64oNe4L8R+qPPW492nHNEz6jy/BhVRTnML8qmqih77Hn0C2BeYTbZUX0ByMR0hqrIHNAdH+RkZ5wTnfE3nrv6zlmf6AugNC/G/MJs5hVmUVmQTUVBFpWFWVQWZFFRkO09Z+lLIEB0hqpIGinIjlKQHWXZvILz9ukdGBoL+kTo940tt3TH2XW8i9Nn+8+Z+x9VmB2hsvCNsK8sSHwZVBYm1ivysyjNi1GcG9OZvQGhcBdJE7mxCEsq8i94G8PhEceZngFauuO0dPfT2tX/xnJ3Py3d/bx6tJ2Wrn76k47zHxWyxF8DZXmJsC/Lj1Gen0VZXozS/ER7eX6MMu/LoDA7oh3Dc5TCXSRAwiFLbIkXZHHlBfo55+iKD9HaHaelq5/TPQOcOdtPW88Ap88O0Ha2nzM9A2N/DXSP2yE8Kho2yvKyKMuPUZp37hdBaW7iL4Hi3CgluTFKcqMU58aIRXTbxdmgcBfJQGZGUU6UopwoSyvPPxU0qn9omPaeQU57XwCj4Z/8RXC6Z4BDp3toOztwzolg4+XFwueEfnL4F3nPJeNeL8yOEtJ00UVRuIvIpLIiYeYXhZlflNo9cHsHhmjvHaS9Z4DOvkHaewdo7x2ko8d77h2gvXeAjr5Bmjv6aO9N9Dvf8R0hS5wtnBz6RTlRCkcf2REKvS+rwuwohTkRCrOjFOVGyY9FMvKLQeEuItMuNxYhNxZhYXFOyv9meMTRlfRF0Nk3QHtPYr2j943njr4BTnTG2Xuym66+Qbr7J54yGmUGBVnnCf+JvhyS+hTlRMmJhtNyv4LCXUTmhHDIKMmLXfTF2oZHHGfjQ3TFB+nsG6Srb5Cu+CBdfePbhujqS6wfOt0z9nrvwPmnkAAiIaMwJ0pBdoT8rIj3nFh/oy1KfnaEwuR1r+9on0h4dvc1KNxFJK2FQ0ZRbmIKpmby7r9hYGiE7vi54Z/85TDadrZ/iO74EGfjQzS193K2f2isbXii40/HyYmGyffC/o/ftpx11yy4hGpTp3AXkYwWi4Qoy8+iLD/rkv69c4744Ajd/YNj4d8dH+Kst55YHqI7/sYXREnuzN8/QOEuIjIFZkZOLExOLEwKBx7NGh1wKiISQAp3EZEAUriLiASQwl1EJIAU7iIiAaRwFxEJIIW7iEgAKdxFRALIt9vsmVkrcOQS/3k5cHoay0kHGnNm0Jgzw1TGvNg5VzFZJ9/CfSrMrCGVewgGicacGTTmzDAbY9a0jIhIACncRUQCKF3D/XG/C/CBxpwZNObMMONjTss5dxERubB03XIXEZELSLtwN7O7zGyfmTWa2UN+1zMVZvYNM2sxs51JbaVm9oyZ7feeS7x2M7O/9ca93cyuS/o393v995vZ/X6MJRVmVmNmz5nZbjPbZWZ/5LUHeczZZvaKmW3zxvwXXnudmW3yxvZdM4t57VneeqP3em3Sz3rYa99nZr/lz4hSZ2ZhM9tqZj/x1gM9ZjM7bGY7zOw1M2vw2vz7bDvn0uYBhIEDwBIgBmwDVvpd1xTG8xbgOmBnUtujwEPe8kPAF73ldwA/Awy4HtjktZcCB73nEm+5xO+xnWe8VcB13nIB8DqwMuBjNiDfW44Cm7yxfA9Y77V/Bfi4t/yHwFe85fXAd73lld7nPQuo8/4fhP0e3yRj/zTwHeAn3nqgxwwcBsrHtfn22fb9F3KRv7wbgI1J6w8DD/td1xTHVDsu3PcBVd5yFbDPW/4qcN/4fsB9wFeT2s/pN5cfwL8Cd2bKmIFc4FXgzSROYIl47WOfa2AjcIO3HPH62fjPenK/ufgAqoFfAHcAP/HGEPQxTxTuvn22021aZiFwLGm9yWsLknnOuRPe8klgnrd8vrGn5e/E+9P7WhJbsoEeszc98RrQAjxDYgu0wzk35HVJrn9sbN7rnUAZaTZm4K+B/wyMeOtlBH/MDvg3M9tiZg94bb59tnUP1TnMOefMLHCHM5lZPvBD4I+dc11mNvZaEMfsnBsGVptZMfAj4AqfS5pRZvYuoMU5t8XMbvO7nll0s3Ou2cwqgWfMbG/yi7P92U63LfdmoCZpvdprC5JTZlYF4D23eO3nG3ta/U7MLEoi2L/tnPsXrznQYx7lnOsAniMxJVFsZqMbV8n1j43Ne70IaCO9xnwTsM7MDgNPkJia+RuCPWacc83ecwuJL/G1+PjZTrdw3wws8/a6x0jsfNngc03TbQMwuof8fhLz0qPtH/D2sl8PdHp/7m0E3m5mJd6e+Ld7bXOOJTbRvw7scc59KemlII+5wttix8xySOxj2EMi5N/tdRs/5tHfxbuBZ11i8nUDsN47sqQOWAa8MjujuDjOuYedc9XOuVoS/0efdc79PgEes5nlmVnB6DKJz+RO/Pxs+70T4hJ2WryDxFEWB4DP+l3PFMfyz8AJYJDE3NpHSMw1/gLYD/wcKPX6GvCYN+4dQH3Sz/kw0Og9PuT3uC4w3ptJzEtuB17zHu8I+JhXAVu9Me8EHvHal5AIqkbg+0CW157trTd6ry9J+lmf9X4X+4C7/R5biuO/jTeOlgnsmL2xbfMeu0azyc/Pts5QFREJoHSblhERkRQo3EVEAkjhLiISQAp3EZEAUriLiASQwl1EJIAU7iIiAaRwFxEJoP8PGGJQ05e7lA4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.4611,  0.0910,  0.4005,  0.0474])\n",
      "tensor([ 1.,  0.,  0.,  0.])\n",
      "0.1676856428384781\n"
     ]
    }
   ],
   "source": [
    "all_losses = np.array(all_losses, dtype = np.float)\n",
    "all_losses\n",
    "plt.plot(all_losses)\n",
    "plt.show()\n",
    "print(pred[3])\n",
    "print(labels_train_v[3])\n",
    "print(all_losses[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy result from testing data on the model\n",
    "\n",
    "Now we fit the test dataset on our model and find the score of each correctly labeled data by the Neural Network model and find the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy Score is 86.57407407407408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritvikkhanna/VirtualEnvironments/PyTorch/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predicted_values = []\n",
    "for num in range(len(feature_test_v)):\n",
    "    predicted_values.append(model(feature_test_v[num]))\n",
    "\n",
    "    \n",
    "    score = 0\n",
    "for num in range(len(predicted_values)):\n",
    "    if np.argmax(labels_test[num]) == np.argmax(predicted_values[num].data.numpy()):\n",
    "        score = score + 1\n",
    "accuracy = float(score / len(predicted_values)) * 100\n",
    "print ('Testing Accuracy Score is ' + str(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
